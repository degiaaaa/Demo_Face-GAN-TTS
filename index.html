<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Face-GAN-TTS – Audio Demo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    html,body{height:100%;margin:0;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif;line-height:1.5;background:#fff;color:#111}
    main{max-width:1000px;margin:0 auto;padding:2rem 1rem}
    h1{text-align:center;margin-bottom:1.25rem;font-size:clamp(1.8rem,4vw,2.4rem)}
    figure{margin:0 auto 2rem;display:flex;flex-direction:column;align-items:center;width:min(100%,640px)}
    .spectrogram{width:100%;aspect-ratio:953/768;background:url("./demo_files/compare_gt_gan_scratch_finetune_2x2_spk1263_00003.png") center/contain no-repeat;border:1px solid #ddd;border-radius:0.5rem}
    figcaption{font-size:0.9rem;margin-top:0.5rem;color:#444;text-align:center}
    .audio-block{margin:1.5rem 0;display:flex;flex-direction:column;align-items:center;gap:0.5rem}
    audio{width:100%;max-width:640px;border-radius:0.5rem;background:rgba(255,255,255,0.85);padding:0.5rem}
    section{margin-top:3rem}
    h2{font-size:clamp(1.3rem,3vw,1.8rem);margin-bottom:0.75rem}
    ul{padding-left:1.25rem}
    li{margin-bottom:0.5rem}
    a{color:#0658c2}
  </style>
</head>
<body>
  <main>
    <h1>Face-GAN-TTS: An Adversarial-Diffusion Framework for Generating High-Quality Voices from Faces</h1>

    <!-- Mel-spectrogram figure -->
    <figure>
      <div class="spectrogram" role="img" aria-label="Comparison of different training variants in the Mel spectrogram"></div>
      <figcaption>Figure 1: Mel-spectrogram comparison – (a) Ground Truth, (b) Face-GAN-TTS, (c) FACE-TTS Scratch, (d) FACE-TTS Finetuned, (e) FACE-TTS trained on LRS3.</figcaption>
    </figure>

    <!-- Audio samples -->
    <div class="audio-block">
      <strong>(b) Face-GAN-TTS</strong>
      <audio controls>
        <source src="demo_files/FACEGANTTS_spk1263_00003.wav" type="audio/wav" />
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="audio-block">
      <strong>(c) FACE-TTS Scratch</strong>
      <audio controls>
        <source src="demo_files/FACETTS_scratch_spk1263_00003.wav" type="audio/wav" />
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="audio-block">
      <strong>(d) FACE-TTS Finetuned</strong>
      <audio controls>
        <source src="demo_files/FACETTS_finetuned_spk1263_00003.wav" type="audio/wav" />
        Your browser does not support the audio element.
      </audio>
    </div>

    <div class="audio-block">
      <strong>(e) FACE-TTS trained on LRS3</strong>
      <audio controls>
        <source src="demo_files/FACETTS_LRS3_ONLY_spk1263_00003.wav" type="audio/wav" />
        Your browser does not support the audio element.
      </audio>
    </div>

    <!-- Ethical considerations -->
    <section id="ethics">
      <h2>Ethical Considerations</h2>
      <ul>
        <li><strong>Privacy & Consent:</strong> All faces originate from LRS2 BBC Television dataset that permit research use but not demonstation.</li>
        <li><strong>Deepfake Risks:</strong> This technology  should not be misused for deception and is not intended to impersonate real people. </li>
        <li><strong>Bias & Fairness:</strong> We evaluate the model on the Chicago Face Database to expose potential biases. This Technology has limitations regarding demographic features.</a>.</li>
        <li><strong>Responsible Release:</strong> Audio data are provided solely for scientific reproduction—no commercial use without explicit permission.</li>
      </ul>
    </section>

    <!-- References -->
    <section id="references">
      <h2>Referenced Projects & Citations</h2>
      <ul>
        <li>Lee <em>et al.</em>, “<em>Lee, J., Chung, J. S., and Chung, S.-W. (2023). Imaginary voice: Face-styled diffusion model for text-to-speech. <a href="https://facetts.github.io">Project page</a></li>
        <li>Kong, J., Kim, J., and Bae, J. (2020a). Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis. Advances in neural information processing systems, 33, 17022–17033.</li>
        <li>Ko, M., Kim, E., and Choi, Y.-H. (2024). Adversarial training of denoising diffusion model using dual discriminators for high-fidelity multi-speaker tts. IEEE Open Journal of Signal Processing, 5, 577–587.</li>
        <li>Ma, D. S., Correll, J., and Wittenbrink, B. (2015). The chicago face database: A free stimulus set of faces and norming data. Behavior research methods, 47, 1122–1135.</li>
        <li>Afouras, T., Chung, J. S., Senior, A. W., Vinyals, O., and Zisserman, A. (2018a). Deep audio-visual speech recognition. CoRR, abs/1809.02108.</li>
      </ul>
      <p>The full source code for this demo is available on <a href="https://github.com/CognitiveModeling/Face-GAN-TTS.git">GitHub</a>.</p>
    </section>

  </main>
</body>
</html>